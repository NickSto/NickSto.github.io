{"hash":"64a9e8afa68c1466f7ef441294c96aecf9a68066","data":{"article":{"id":"38b62cf037a2a7ea85e31a08096c4b1c","title":"Deploy an Instance of Galaxy on Google Kubernetes Engine","tease":"","category":null,"date":null,"days":null,"contact":"","contact_url":"","authors":"","location":"","location_url":"","source_blog":"","source_blog_url":"","skip_title_render":null,"links":[],"image":"","images":{},"external_url":"","content":"<div class=\"toc-wrapper col-md-3\">\n<ul>\n<li><a href=\"#create-a-cluster\">Create a Cluster</a></li>\n<li><a href=\"#install-helm\">Install Helm</a></li>\n<li><a href=\"#deploy-galaxy-on-the-cluster\">Deploy Galaxy on the Cluster</a></li>\n<li><a href=\"#access-galaxy\">Access Galaxy</a></li>\n<li><a href=\"#delete-resources-and-gke-cluster\">Delete Resources and GKE cluster</a></li>\n</ul>\n</div>\n<div class=\"body-wrapper col-md-9\">\n<p>We break the steps of deploying a Galaxy instance on\n<a href=\"https://cloud.google.com/kubernetes-engine/\" target=\"_blank\" rel=\"noopener noreferrer\">Google Kubernetes Engine (GKE)</a>\nto the following sections:</p>\n<ul>\n<li><a href=\"#create-a-cluster\">Create a K8s cluster</a>;</li>\n<li><a href=\"#install-helm\">Install and configure Helm</a>;</li>\n<li><a href=\"#deploy-galaxy-on-the-cluster\">Deploy an instance of Galaxy using Helm charts</a>;</li>\n<li><a href=\"#access-galaxy\">Access Galaxy</a>;</li>\n<li><a href=\"#delete-resources-and-gke-cluster\">Delete cluster</a>.</li>\n</ul>\n<blockquote>\n<p>Note that all the commands given in this tutorial have been tested in\n<a href=\"https://cloud.google.com/shell/\" target=\"_blank\" rel=\"noopener noreferrer\"><em>Cloud shell</em></a>; however, they may be\napplicable to any console where the\n<a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\" target=\"_blank\" rel=\"noopener noreferrer\">K8s command-line tool (<code>kubectl</code>)</a>\nis installed and configured.</p>\n</blockquote>\n<h1 id=\"create-a-cluster\"><a href=\"#create-a-cluster\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Create a Cluster</h1>\n<p>To create a GKE cluster, you may follow tutorials such as\n<a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/creating-a-cluster\" target=\"_blank\" rel=\"noopener noreferrer\">this</a> or\n<a href=\"https://cloud.google.com/kubernetes-engine/docs/quickstart\" target=\"_blank\" rel=\"noopener noreferrer\">this</a>.\nAlternatively, you may run the following steps:</p>\n<ol>\n<li>Goto <a href=\"https://console.cloud.google.com/projectselector/kubernetes?_ga=2.101714888.-830640031.1571682936\" target=\"_blank\" rel=\"noopener noreferrer\">K8s Engine page</a>.</li>\n<li>Select a project, or create one if you already do not have one.</li>\n<li>On the top-right, click on the <code>Activate Cloud Shell [>_]</code> button, and\n<strong>keep this shell open as all the following commands are executed in this window</strong>.</li>\n<li>\n<p>Run the following commands in the opened shell:</p>\n<ol>\n<li>Configure project name:\n<code>$ gcloud config set project &#x3C;PROJECT NAME></code>\nReplace <code>&#x3C;PROJECT_NAME></code> with your selected project name.</li>\n<li>\n<p>Configure zone (e.g., us-central1-a):</p>\n<pre><code>$ gcloud config set compute/zone &#x3C;ZONE>\n</code></pre>\n<p>Replace <code>&#x3C;ZONE></code> with your zone preference; you may get a list of\navailable zones using the following command:</p>\n<pre><code>$ gcloud compute zones list\n</code></pre>\n</li>\n<li>\n<p>Create cluster:</p>\n<pre><code>$ gcloud container clusters create &#x3C;CLUSTER_NAME> --cluster-version=1.13.7-gke.24 --num-nodes=1 --machine-type=n1-standard-32\n</code></pre>\n<p>The specific arguments are:</p>\n<ul>\n<li>Replace <code>&#x3C;CLUSTER_NAME></code> with your name preference.</li>\n<li><code>cluster-version</code>: the instructions on this page are tested using\n<code>--cluster-version=1.13.7-gke.24</code> for their compatibility\n(with <code>helm</code>, discussed later on this page).</li>\n<li><code>num-nodes</code>: the instructions on this page are compatible with a\nsingle-node cluster (i.e., <code>--num-nodes=1</code>). A multi-node\ncluster setup requires additional steps discussed in the following,\n<strong>if you increment the number of nodes, make sure these configuration\nare implemented</strong>.</li>\n</ul>\n<p><strong>Multi-node cluster</strong>: The cluster's default <code>storageClass</code> (which is\nusually supports <code>ReadWriteOnce</code> access mode) will be used. If you\nset-up a cluster with multiple nodes, a <code>storageClass</code> that supports\n<code>ReadWriteMany</code> access mode should be available on the cluster, and\nshould be set using <code>--set presistence.storageClass=[storageClassName]</code>\n(leaving <code>accessMode=ReadWriteMany</code>). We recommend using the\n<a href=\"https://github.com/helm/charts/tree/master/stable/nfs-server-provisioner\" target=\"_blank\" rel=\"noopener noreferrer\">NFS-Provisioner</a>\nfor a multi-node setup.</p>\n<ul>\n<li>\n<p><code>machine-type</code>: the default machine type (i.e., <code>n1-standard-1</code>) can be considered\nsuboptimal for Galaxy requirements, hence we set the machine type to <code>n1-standard-32</code>\nin this example. You may choose a machine type that serves best your requirements and\nzone selection. You may obtain a list of available machine type using the following\ncommand:</p>\n<pre><code>$ gcloud compute machine-types list\n</code></pre>\n</li>\n</ul>\n<p>You may refer to <a href=\"https://cloud.google.com/sdk/gcloud/reference/container/clusters/create\" target=\"_blank\" rel=\"noopener noreferrer\">this page</a>\nfor a complete list of the <code>gcloud</code> command arguments.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"install-helm\"><a href=\"#install-helm\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Install Helm</h1>\n<p><a href=\"https://helm.sh\" target=\"_blank\" rel=\"noopener noreferrer\">Helm</a> is a K8s package manager, which is composed of two\ncomponents: client (<a href=\"https://helm.sh/docs/install/\" target=\"_blank\" rel=\"noopener noreferrer\"><em>helm</em></a>) and\nserver (<a href=\"https://helm.sh/docs/glossary/#tiller\" target=\"_blank\" rel=\"noopener noreferrer\"><em>tiller</em></a>).</p>\n<p>In order to deploy a Galaxy instance on a K8s cluster, a <code>helm</code> and <code>tiller</code>\ninstallations on the cluster are required. You may already have <code>helm</code> and <code>tiller</code>\ninstalled on the cluster; you may run the following command to ensure they are\nproperly installed:</p>\n<pre><code>$ helm version\n</code></pre>\n<p>If the output is as the following, you would need to configure <code>tiller</code>:</p>\n<pre><code>Client: &#x26;version.Version{SemVer:\"v2.14.1\", GitCommit:\"5270352a09c7e8b6e8c9593002a73535276507c0\", GitTreeState:\"clean\"}\nError: could not find tiller\n</code></pre>\n<p>In order to install <code>helm</code> and <code>tiller</code>, run the following commands\nin the <a href=\"https://cloud.google.com/shell/\" target=\"_blank\" rel=\"noopener noreferrer\"><em>Cloud shell</em></a>:</p>\n<pre><code>$ wget https://storage.googleapis.com/kubernetes-helm/helm-v2.14.1-linux-amd64.tar.gz\n$ tar zxfv helm-v2.14.1-linux-amd64.tar.gz\n$ sudo cp linux-amd64/helm /usr/local/bin/helm\n$ kubectl create clusterrolebinding user-admin-binding --clusterrole=cluster-admin --user=$(gcloud config get-value account)\n$ kubectl create serviceaccount tiller --namespace kube-system\n$ kubectl create clusterrolebinding tiller-admin-binding --clusterrole=cluster-admin --serviceaccount=kube-system:tiller\n$ helm init --service-account=tiller\n$ helm repo update\n$ rm helm-v2.14.1-linux-amd64.tar.gz\n$ rm -r linux-amd64/\n</code></pre>\n<p>You may re-run the following command to ensure Helm client and server successful installation:</p>\n<pre><code>$ helm version\nClient: &#x26;version.Version{SemVer:\"v2.14.1\", GitCommit:\"5270352a09c7e8b6e8c9593002a73535276507c0\", GitTreeState:\"clean\"}\nServer: &#x26;version.Version{SemVer:\"v2.14.1\", GitCommit:\"5270352a09c7e8b6e8c9593002a73535276507c0\", GitTreeState:\"clean\"}\n</code></pre>\n<p>Additionally, you may run the following command to ensure a <code>tiller</code>\n<a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod/\" target=\"_blank\" rel=\"noopener noreferrer\">pod</a> is running:</p>\n<pre><code>$ kubectl -n kube-system get pods\nNAME                                READY   STATUS    RESTARTS   AGE\ntiller-deploy-6d65d78679-xr9f4      1/1     Running   0          3m17s\n</code></pre>\n<p>If the helm <code>tiller</code> pod is not running, you may re-install it using the\nfollowing commands:</p>\n<pre><code>$ helm reset\n$ kubectl create clusterrolebinding user-admin-binding --clusterrole=cluster-admin --user=$(gcloud config get-value account)\n$ kubectl create serviceaccount tiller --namespace kube-system\n$ kubectl create clusterrolebinding tiller-admin-binding --clusterrole=cluster-admin --serviceaccount=kube-system:tiller\n$ helm init --service-account=tiller\n$ helm update\n</code></pre>\n<h1 id=\"deploy-galaxy-on-the-cluster\"><a href=\"#deploy-galaxy-on-the-cluster\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Deploy Galaxy on the Cluster</h1>\n<p>The deployment of Galaxy on a K8s cluster consists of two steps discussed as it follows.</p>\n<ol>\n<li>\n<p>[Optional] Deploy the <a href=\"https://cernvm.cern.ch/portal/filesystem\" target=\"_blank\" rel=\"noopener noreferrer\">CernVM File System (CVMFS)</a>\nservice using <a href=\"https://github.com/CloudVE/galaxy-cvmfs-csi-chart\" target=\"_blank\" rel=\"noopener noreferrer\">CVMFS-CSI chart</a>.\nYou may run the following commands for this deployment:</p>\n<pre><code>$ git clone https://github.com/CloudVE/galaxy-cvmfs-csi-chart.git\n$ helm install galaxy-cvmfs-csi-chart/galaxy-cvmfs-csi/ --namespace=cvmfs --name=gxy-cvmfs\n</code></pre>\n<p>If you get an error saying <code>Error: no available release name found</code>,\nyou may take the following steps:</p>\n<ul>\n<li>first <a href=\"https://helm.sh/docs/helm/#helm-reset\" target=\"_blank\" rel=\"noopener noreferrer\">reset <code>helm</code></a>, then\nre-run the aforementioned <code>helm install</code> command.</li>\n<li>if resetting <code>helm</code> does not resolve the error, you may run the following commands:</li>\n</ul>\n<pre><code>$ kubectl create serviceaccount --namespace kube-system tiller\n$ kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller\n$ kubectl patch deploy --namespace kube-system tiller-deploy -p '{\"spec\":{\"template\":{\"spec\":{\"serviceAccount\":\"tiller\"}}}}'\n</code></pre>\n</li>\n<li>\n<p>Deploy Galaxy helm chart using the following commands:</p>\n<pre><code>$ git clone https://github.com/galaxyproject/galaxy-helm.git\n$ cd galaxy-helm/galaxy\n$ helm dependency update\n$ helm install . --set persistence.accessMode=ReadWriteOnce --set service.type=LoadBalancer --set service.port=80 --set ingress.enabled=false -f values-cvmfs.yaml --name gxy --namespace gxy-namespace\n$ kubectl config set-context --current --namespace=gxy-namespace\n</code></pre>\n<p>At this point, wait for about 8 minutes, and then check the status of the pods\nif all are scheduled and running using the following command:</p>\n<pre><code>$ kubectl get pods\nNAME                              READY   STATUS    RESTARTS   AGE\ngxy-galaxy-job-685ddbbf4b-7n8cx   1/1     Running   0          9m\ngxy-galaxy-postgres-0             1/1     Running   0          9m\ngxy-galaxy-web-555db6bcfb-2gwkh   1/1     Running   2          9m\n</code></pre>\n</li>\n</ol>\n<h1 id=\"access-galaxy\"><a href=\"#access-galaxy\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Access Galaxy</h1>\n<p>The deployed Galaxy can be accessed after the load balancer is ready,\nwhich may take few minutes to be ready. The load balancer status can be\nchecked using the following command:</p>\n<pre><code>$ kubectl get svc gxy-galaxy\nNAME         TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)        AGE\ngxy-galaxy   LoadBalancer   10.43.245.53   104.198.225.7   80:30597/TCP   15m\n</code></pre>\n<p>The deployed Galaxy instance can be accessed from the following address:</p>\n<pre><code>http://&#x3C;EXTERNAL-IP>:80\n</code></pre>\n<p>The <code>EXTERNAL-IP</code> address can be obtained from the output of the previous command.\nFor instance, the deployed Galaxy instance of this tutorial is accessible from the\nfollowing IP address:</p>\n<pre><code>http://104.198.225.7:80\n</code></pre>\n<h1 id=\"delete-resources-and-gke-cluster\"><a href=\"#delete-resources-and-gke-cluster\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Delete Resources and GKE cluster</h1>\n<ol>\n<li>\n<p>You may <code>uninstall</code> the Galaxy helm chart release using the following command:</p>\n<pre><code>$ helm del --purge my-gxy\n</code></pre>\n<p>If you also deployed the CVMFS-CSI Chart, you may also delete that release:</p>\n<pre><code>$ helm del --purge gxy-cvmfs\n</code></pre>\n</li>\n<li>\n<p>If the <code>reclaimPolicy</code> of PVCs is <code>delete</code>, all resources deployed will be\ndeleted with the exception of the <code>Postgres</code> data PVC and Volume.\nIf you wish to delete this volume as well, use:</p>\n<pre><code>kubectl --namespace mynamespace get pvc\nkubectl delete pvc data-my-gxy-galaxy-postgres-0 --namespace mynamespace\n</code></pre>\n</li>\n<li>\n<p>Delete cluster:</p>\n<p>You can delete the cluster either through the GKE dahsboard, or by using the\nfollowing command:</p>\n<pre><code>gcloud container clusters delete [CLUSTER_NAME]\n</code></pre>\n<p>More info on deleting a GKE cluster can be found at the <a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/deleting-a-cluster\" target=\"_blank\" rel=\"noopener noreferrer\">GKE docs</a>.</p>\n</li>\n</ol>\n</div>\n"}},"context":{}}