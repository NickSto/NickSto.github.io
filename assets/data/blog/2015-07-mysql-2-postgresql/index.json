{"hash":"14e186fd360947c1255e65c919a062692f477385","data":{"article":{"id":"5433a790767978e7b8fbf26e770b7e2c","title":"Moving from MySQL to PostgreSQL","tease":"It is pretty simple, though you might hit some obstacles depending on how old your MySQL server is and how much you have manually interfered with the database.","image":"","images":{},"category":"blog","contact":"","date":"30 July 2015","content":"<p>After running our Galaxy servers successfully with MySQL as the backend database server for several years, we decided to switch to the recommended PostgreSQL server.</p>\n<h2 id=\"summary\"><a href=\"#summary\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Summary</h2>\n<p>I used the tool <a href=\"https://pypi.python.org/pypi/py-mysql2pgsql\" target=\"_blank\" rel=\"noopener noreferrer\">py-mysql2pgsql</a> to generate table dumps from our MySQL database. I then imported table by table into an empty by Galaxy created PostgreSQL database. After setting the \"sequences\", the database was ready to go.</p>\n<h2 id=\"learning-postgresql\"><a href=\"#learning-postgresql\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Learning PostgreSQL</h2>\n<p>Our institute used mostly MySQL. At the start, I also had hardly any experience with PostgreSQL, and I gradually had to learn everything. On top of using google searches, this book helped me a lot: <a href=\"http://shop.oreilly.com/product/0636920025061.do\" target=\"_blank\" rel=\"noopener noreferrer\">PostgreSQL: Up and Running</a> by Regina Obe and Leo Hsu. I installed a few test galaxy servers from scratch using PostgreSQL as their backend database trying to learn the basics of PostgreSQL and the 'quirks' of the Galaxy database schema. I wished, I had knew about the nice <a href=\"https://galaxyproject.org/schema/SchemaSpy/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">page generated with SchemaSpy</a> presented by <a href=\"https://wiki.galaxyproject.org/DaveClements\" target=\"_blank\" rel=\"noopener noreferrer\">Dave Clements</a> at <a href=\"http://gcc2015.tsl.ac.uk/training-day/#The_Galaxy_Database_Schema\" target=\"_blank\" rel=\"noopener noreferrer\">GCC 2015</a>, when I started my journey.</p>\n<p>I quickly realized a simple dump table from MySQL and load them into PostgreSQL will not work. The database schema could not be converted one to one from MySQL to PostgreSQL and the contents of the table could not be dumped and loaded one to one from MySQL to PostgreSQL (a simple example: MySQl stores boolean as '0' or '1', PostgreSQL as 'f' or 't') .</p>\n<h2 id=\"preparations-for-the-move\"><a href=\"#preparations-for-the-move\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Preparations for the Move</h2>\n<p>To make sure, the new PostgreSQL database had the correct schema, I set up a new Galaxy server from scratch, using the same release as our production server was running at the time (<a href=\"http://galaxy.readthedocs.org/en/master/releases/15.03_announce.html\" target=\"_blank\" rel=\"noopener noreferrer\">15.03</a>), and pointing to a new, empty PostgreSQL database. By starting the new Galaxy server, the 128 migration steps were executed, and the PostgreSQL database was populated with 156 empty (see also below) tables.</p>\n<p>I used the tool <a href=\"https://pypi.python.org/pypi/py-mysql2pgsql\" target=\"_blank\" rel=\"noopener noreferrer\">py-mysql2pgsql</a> to generate table dumps from our MySQL database. By default, <a href=\"https://pypi.python.org/pypi/py-mysql2pgsql\" target=\"_blank\" rel=\"noopener noreferrer\">py-mysql2pgsql</a> imports the data into a  PostgreSQL database, but if you provide a file name (e.g. \"mysql2pgsql.txt\") in the required \"mysql2pgsql.yml\" file, the output goes to the \"mysql2pgsql.txt\" file. This file contains all the commands to create a PostgreSQL database, based on the information from the MySQL database. Since I was only interested in the loading data (or rather \"COPY\") parts, I used a simple perl script to parse \"mysql2pgsql.txt\" to get the \"COPY\" statements for all table which had data in.</p>\n<pre><code>#!/usr/bin/perl\n\nuse warnings;\nuse strict;\n\nmy $file = \"mysql2pgsql.txt\";\n\nopen(DUMP, $file); \n\nmy $control = 0;\nmy $newfile; \nwhile ( &#x3C;DUMP> ) {\n\n    if ($_ =~ /^COPY \\\"(.*)\\\" \\(/) {\n        $newfile = \"mysql2pgsql.\".$1.\".txt\";\n        print $newfile.\"\\n\";\n        open(OUT,\">$newfile\");\n        print OUT $_;\n    }   \n    if ($_ =~ /&#x3C;sup>[0-9]/ || $_ =~ /&#x3C;/sup>Galaxy/) {\n        print OUT $_;\n        $control++;\n\n    }   \n    if ($_ =~ /^\\\\\\./) {\n        print OUT $_;   \n        close OUT;\n        if ($control == 0) {\n            system(\"rm -f $newfile\");\n        }\n        $control =0;\n    }\n}\nclose DUMP;\n</code></pre>\n<p>This script generated 81 copy statements for the database used for our production server.</p>\n<h2 id=\"loading-the-data\"><a href=\"#loading-the-data\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Loading the Data</h2>\n<p>As a PostgreSQL novice coming from the simple world of MySQL MyISAM tables, I had to learn how to deal with foreign keys. There were probably better ways to do this, but I decided to figure out the insertion order myself. Nowadays, I would check this <a href=\"https://galaxyproject.org/schema/SchemaSpy/insertionOrder.txt\" target=\"_blank\" rel=\"noopener noreferrer\">page for the insertion order</a> or deactivate the keys table by table (see <a href=\"http://www.postgresql.org/message-id/4EA2057F.3000002@ringerc.id.au\" target=\"_blank\" rel=\"noopener noreferrer\">this question/answer</a>) or \"DROP\" all keys first and \"ADD\" the constraints back after loading all the data.</p>\n<p>I could \"COPY\" the data for all tables without any problems. But before the database was ready to go, I had to set the \"sequences\" (see <a href=\"http://stackoverflow.com/questions/9108833/postgres-autoincrement-not-updated-on-explicit-id-inserts\" target=\"_blank\" rel=\"noopener noreferrer\">here for an explanation</a>). At this point, I didn't know, which tables had such an autoincrement feature. In order to figure out, I created a complete database dump from the PostgreSQL database with <a href=\"http://www.postgresql.org/docs/9.4/static/app-pgdump.html\" target=\"_blank\" rel=\"noopener noreferrer\">pg_dump</a> using the options \"-f postgresql.dump\" (send output to this file) and \"-F p\" (plain text). In the file \"postgresql.dump\", I searched for the \"SEQUENCE\" command and created for each a \"SELECT setval\" statement with the following perl script:</p>\n<pre><code>#!/usr/bin/perl\n\nuse warnings;\nuse strict;\n\nmy $file = \"postgresql.dump\";\n\nopen(DUMP, $file); \n\nmy $control = 0;\nmy $newfile = \"fix_sequence.txt\";\n\nopen(FIX, \">$newfile\"); \n\nwhile ( &#x3C;DUMP>) {\n\n    if ($_ =~ /^CREATE SEQUENCE ((.*)_id_seq)/) {\n        my $sequence = $1;\n        my $table = $2;\n        print FIX \"SELECT setval('\".$sequence.\"', (SELECT MAX(id) from \\\"\".$table.\"\\\"));\";\n        print FIX \"\\n\\n\";\n    }\n}\n\nclose DUMP;\nclose FIX;\n</code></pre>\n<p>I only used the \"SELECT setval\" commands for tables I loaded with data before.</p>\n<h2 id=\"problems-i-was-running-into\"><a href=\"#problems-i-was-running-into\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Problems I was running into</h2>\n<h5 id=\"circular-foreign-keys\"><a href=\"#circular-foreign-keys\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>circular foreign keys</h5>\n<p>I run into three circular foreign key constraints in the (empty) PostgreSQL database:</p>\n<ul>\n<li>workflow &#x3C;-> stored_worflow (see: <a href=\"https://galaxyproject.org/schema/SchemaSpy/tables/workflow.html\" target=\"_blank\" rel=\"noopener noreferrer\">workflow</a>)</li>\n<li>library_dataset &#x3C;-> library_dataset_dataset_association &#x3C;-> history_dataset_association_dataset (see: <a href=\"https://galaxyproject.org/schema/SchemaSpy/tables/library_dataset_dataset_association.html\" target=\"_blank\" rel=\"noopener noreferrer\">library_dataset_dataset_association.html</a></li>\n<li>form_definition &#x3C;-> form_definition_current (see: <a href=\"https://galaxyproject.org/schema/SchemaSpy/tables/form_definition.html\" target=\"_blank\" rel=\"noopener noreferrer\">form_definition</a>)</li>\n</ul>\n<p>I solved it by dropping the constraint, uploading the data, and recreating the foreign key, eg:</p>\n<pre><code>ALTER TABLE workflow DROP CONSTRAINT workflow_stored_workflow_id_fkey;\n\n# 'COPY' workflow table\n# 'COPY' stored_workflow table\n\nALTER TABLE ONLY workflow ADD CONSTRAINT workflow_stored_workflow_id_fkey FOREIGN KEY (stored_workflow_id) REFERENCES stored_workflow(id);\n</code></pre>\n<pre><code>ALTER TABLE library_dataset DROP CONSTRAINT library_dataset_dataset_association_id_fk;\n\n# 'COPY' library_dataset table\n\nALTER TABLE library_dataset_dataset_association DROP CONSTRAINT history_dataset_association_dataset_id_fkey;\n\n# 'COPY' library_dataset_dataset_association table\n# 'COPY' history_dataset_association table\n\nALTER TABLE ONLY library_dataset ADD CONSTRAINT library_dataset_dataset_association_id_fk FOREIGN KEY (library_dataset_dataset_association_id) REFERENCES library_dataset_dataset_association(id);\n\nALTER TABLE ONLY library_dataset_dataset_association ADD CONSTRAINT history_dataset_association_dataset_id_fkey FOREIGN KEY (copied_from_history_dataset_association_id) REFERENCES history_dataset_association(id);\n</code></pre>\n<pre><code>ALTER TABLE form_definition DROP CONSTRAINT form_definition_form_definition_current_id_fkey;\n\n# 'COPY' form_definition table\n# 'COPY' form_definition_current table\n\nALTER TABLE ONLY form_definition ADD CONSTRAINT form_definition_form_definition_current_id_fkey FOREIGN KEY (form_definition_current_id) REFERENCES form_definition_current(id);\n</code></pre>\n<h5 id=\"tables-already-filled-by-galaxy\"><a href=\"#tables-already-filled-by-galaxy\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>tables already filled by galaxy</h5>\n<p>Obviously, as part of the database generation the table \"migrate_version\" had already been filled in my case:</p>\n<pre><code>=#select * from migrate_version;\n repository_id |     repository_path      | version \n---------------+--------------------------+---------\n Galaxy        | lib/galaxy/model/migrate |     128\n(1 row)\n</code></pre>\n<p>The \"kombu_queue\" table was also not empty:</p>\n<pre><code>=# select * from kombu_queue;\n id |     name     \n----+--------------\n  1 | control.main\n(1 row)\n</code></pre>\n<p>In both cases, the contents was equal to the contents from the dump out of the existing MySQL database.</p>\n<p>The \"migrate_tools\" table is also pre-filled:</p>\n<pre><code>=# select * from migrate_tools;\n repository_id |           repository_path            | version \n---------------+--------------------------------------+---------\n GalaxyTools   | lib/tool_shed/galaxy_install/migrate |       1\n(1 row)\n</code></pre>\n<p>In the our current MySQl databes, the version was '12'. The version had to be set to '12' in the new PostgrSQL database, otherwise it would cause troubles when re-starting the Galaxy server.</p>\n<h5 id=\"legacy-from-manual-interfering\"><a href=\"#legacy-from-manual-interfering\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>legacy from manual interfering</h5>\n<p>Our Galaxy instance is pretty old, and hence over the course of the last seven years, I have several times manually fixed some tables in the MySQL database. The biggest intervention, happened, when we switched to external authentication. Several users who used the Galaxy server before and after this switch ended up with two different entries in the galaxy_user table by not using the same e-mail address before, as now returned by the LDAP server (you run into similar issues, when a user asks for a different e-mail address, and the IT folks do not create an alias, but change the entry). Basically, this creates a duplication in the \"galaxy_user\" table.</p>\n<p>At the time, most cases were easy to fix: delete the new user (i.e. the user created with the e-mail address coming from the LDAP server) and change the email address of the existing user, before the <em>new</em> user executes any jobs. However, in one case I must have messed up something and now the foreign key constraints in PostgreSQL were complaining. I had to re-enter a <em>dummy user</em> into the \"galaxy_user\" and \"role\" and add several rows into the \"history\" table before I could upload the data into the new PostgreSQL database.</p>\n<h5 id=\"difference-between-development-and-production-server\"><a href=\"#difference-between-development-and-production-server\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>difference between development and production server</h5>\n<p>I first tested the transition process with our development server. Although, we are trying to keep the development and production server as similar as possible, some features have never been used in the development or in the production server. This has resulted in tables which were empty in the database for the development and populated in the database for the production server - or vice versa.  So I had to adjust the my insertion order.</p>\n<h2 id=\"final-step\"><a href=\"#final-step\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Final Step</h2>\n<p>As the final step, I had to change the database setting in the \"galaxy.ini\" (well, \"universe_wsgi.ini\" for our old instance) and \"reports_wsgi.ini\" files, and restart the server.</p>\n<p>I am sure there are better and easier ways to do this, but the process worked for me. Feel free to contact <a href=\"/people/hansrudolf-hotz/\">me</a>, if you have any questions or want to do such a migration for your Galaxy server as well.</p>\n"}},"context":{}}